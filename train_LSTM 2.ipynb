{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53487505-0628-49d9-81ed-d114691b3980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ideapad GAMING\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all angles to csv\\output.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calculate_angle_2d(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360.0 - angle\n",
    "        \n",
    "    return angle\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def process_video(file_path, class_name, df):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "    pose = mp_pose.Pose()\n",
    "    frame_data = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            try:\n",
    "                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, \n",
    "                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, \n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, \n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, \n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, \n",
    "                       landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "                left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, \n",
    "                        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "                \n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "                right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "                right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "                right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "                right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "\n",
    "\n",
    "\n",
    "                right_shoulder_angle = calculate_angle_2d(right_hip, right_shoulder, right_elbow)\n",
    "                right_elbow_angle = calculate_angle_2d(right_shoulder, right_elbow, right_wrist)\n",
    "                right_hip_angle = calculate_angle_2d(right_knee, right_hip, right_shoulder)\n",
    "                right_knee_angle = calculate_angle_2d(right_hip, right_knee, right_ankle)\n",
    "                                \n",
    "                \n",
    "                left_shoulder_angle = calculate_angle_2d(left_hip, left_shoulder, left_elbow)\n",
    "                left_elbow_angle = calculate_angle_2d(left_shoulder, left_elbow, left_wrist)\n",
    "                left_hip_angle = calculate_angle_2d(left_knee, left_hip, left_shoulder)\n",
    "                left_knee_angle = calculate_angle_2d(left_hip, left_knee, left_ankle)\n",
    "                \n",
    "            except IndexError:\n",
    "                right_shoulder_angle = np.nan\n",
    "                right_elbow_angle = np.nan\n",
    "                right_hip_angle = np.nan\n",
    "                right_knee_angle = np.nan\n",
    "                left_shoulder_angle = np.nan\n",
    "                left_elbow_angle = np.nan\n",
    "                left_hip_angle = np.nan\n",
    "                left_knee_angle = np.nan\n",
    "        else:\n",
    "            right_shoulder_angle = np.nan\n",
    "            right_elbow_angle = np.nan\n",
    "            right_hip_angle = np.nan\n",
    "            right_knee_angle = np.nan\n",
    "            left_shoulder_angle = np.nan\n",
    "            left_elbow_angle = np.nan\n",
    "            left_hip_angle = np.nan\n",
    "            left_knee_angle = np.nan\n",
    "\n",
    "        frame_data.append({\n",
    "            'frame': cap.get(cv2.CAP_PROP_POS_FRAMES),\n",
    "            'right_shoulder_angle' : right_shoulder_angle,\n",
    "            'right_elbow_angle' : right_elbow_angle,\n",
    "            'right_hip_angle' : right_hip_angle,\n",
    "            'right_knee_angle' : right_knee_angle,\n",
    "            'left_shoulder_angle' : left_shoulder_angle,\n",
    "            'left_elbow_angle' : left_elbow_angle,\n",
    "            'left_hip_angle' : left_hip_angle,\n",
    "            'left_knee_angle' : left_knee_angle,\n",
    "            'class_name': class_name\n",
    "        })\n",
    "\n",
    "    cap.release()\n",
    "    df = pd.concat([df, pd.DataFrame(frame_data)], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_folder = 'vid'  # Folder containing the videos\n",
    "    output_folder = 'csv'  # Folder to save CSV files\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Initialize a single DataFrame to hold all data\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Process each video\n",
    "    for file_name in os.listdir(video_folder):\n",
    "        if file_name.endswith('.mp4'):\n",
    "            class_name = file_name.split('_')[0]  # Extract class name from file name\n",
    "            file_path = os.path.join(video_folder, file_name)\n",
    "\n",
    "            # Process the video and append data to the main DataFrame\n",
    "            all_data = process_video(file_path, class_name, all_data)\n",
    "\n",
    "    # Save the consolidated DataFrame to a single CSV file\n",
    "    output_file = os.path.join(output_folder, 'output.csv')\n",
    "    all_data.to_csv(output_file, index=False)\n",
    "    print(f'Saved all angles to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88a7315f-5c35-43ed-bb77-5b3550774580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ideapad GAMING\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all angles to csv\\output.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calculate_angle_2d(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360.0 - angle\n",
    "        \n",
    "    return angle\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def process_video(file_path, class_name, df, desired_fps=60):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = max(1, int(original_fps / desired_fps))  # Ensure frame_interval is at least 1\n",
    "    \n",
    "    pose = mp_pose.Pose()\n",
    "    frame_data = []\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(image)\n",
    "\n",
    "            if results.pose_landmarks:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "                try:\n",
    "                    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, \n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, \n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, \n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, \n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, \n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "                    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, \n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "                    \n",
    "                    right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "                    right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "                    right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "                    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "                    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "                    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "\n",
    "                    right_shoulder_angle = calculate_angle_2d(right_hip, right_shoulder, right_elbow)\n",
    "                    right_elbow_angle = calculate_angle_2d(right_shoulder, right_elbow, right_wrist)\n",
    "                    right_hip_angle = calculate_angle_2d(right_knee, right_hip, right_shoulder)\n",
    "                    right_knee_angle = calculate_angle_2d(right_hip, right_knee, right_ankle)\n",
    "                                    \n",
    "                    left_shoulder_angle = calculate_angle_2d(left_hip, left_shoulder, left_elbow)\n",
    "                    left_elbow_angle = calculate_angle_2d(left_shoulder, left_elbow, left_wrist)\n",
    "                    left_hip_angle = calculate_angle_2d(left_knee, left_hip, left_shoulder)\n",
    "                    left_knee_angle = calculate_angle_2d(left_hip, left_knee, left_ankle)\n",
    "                    \n",
    "                except IndexError:\n",
    "                    right_shoulder_angle = np.nan\n",
    "                    right_elbow_angle = np.nan\n",
    "                    right_hip_angle = np.nan\n",
    "                    right_knee_angle = np.nan\n",
    "                    left_shoulder_angle = np.nan\n",
    "                    left_elbow_angle = np.nan\n",
    "                    left_hip_angle = np.nan\n",
    "                    left_knee_angle = np.nan\n",
    "            else:\n",
    "                right_shoulder_angle = np.nan\n",
    "                right_elbow_angle = np.nan\n",
    "                right_hip_angle = np.nan\n",
    "                right_knee_angle = np.nan\n",
    "                left_shoulder_angle = np.nan\n",
    "                left_elbow_angle = np.nan\n",
    "                left_hip_angle = np.nan\n",
    "                left_knee_angle = np.nan\n",
    "\n",
    "            frame_data.append({\n",
    "                'frame': cap.get(cv2.CAP_PROP_POS_FRAMES),\n",
    "                'right_shoulder_angle' : right_shoulder_angle,\n",
    "                'right_elbow_angle' : right_elbow_angle,\n",
    "                'right_hip_angle' : right_hip_angle,\n",
    "                'right_knee_angle' : right_knee_angle,\n",
    "                'left_shoulder_angle' : left_shoulder_angle,\n",
    "                'left_elbow_angle' : left_elbow_angle,\n",
    "                'left_hip_angle' : left_hip_angle,\n",
    "                'left_knee_angle' : left_knee_angle,\n",
    "                'class_name': class_name\n",
    "            })\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    df = pd.concat([df, pd.DataFrame(frame_data)], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_folder = 'vid'  # Folder containing the videos\n",
    "    output_folder = 'csv'  # Folder to save CSV files\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Initialize a single DataFrame to hold all data\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Process each video\n",
    "    for file_name in os.listdir(video_folder):\n",
    "        if file_name.endswith('.mp4', '.MOV'):\n",
    "            class_name = file_name.split('_')[0]  # Extract class name from file name\n",
    "            file_path = os.path.join(video_folder, file_name)\n",
    "\n",
    "            # Process the video and append data to the main DataFrame\n",
    "            all_data = process_video(file_path, class_name, all_data)\n",
    "\n",
    "    # Save the consolidated DataFrame to a single CSV file\n",
    "    output_file = os.path.join(output_folder, 'output.csv')\n",
    "    all_data.to_csv(output_file, index=False)\n",
    "    print(f'Saved all angles to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f55119d3-9e32-4614-995d-1ab48d1584bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ideapad GAMING\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 12ms/step - accuracy: 0.8392 - loss: 0.4829 - val_accuracy: 0.9859 - val_loss: 0.0565\n",
      "Epoch 2/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.9886 - loss: 0.0465 - val_accuracy: 0.9930 - val_loss: 0.0279\n",
      "Epoch 3/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 0.9951 - loss: 0.0253 - val_accuracy: 0.9974 - val_loss: 0.0117\n",
      "Epoch 4/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 12ms/step - accuracy: 0.9974 - loss: 0.0118 - val_accuracy: 0.9947 - val_loss: 0.0147\n",
      "Epoch 5/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 13ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.9974 - val_loss: 0.0133\n",
      "Epoch 6/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 12ms/step - accuracy: 0.9985 - loss: 0.0088 - val_accuracy: 0.9965 - val_loss: 0.0114\n",
      "Epoch 7/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 12ms/step - accuracy: 0.9975 - loss: 0.0091 - val_accuracy: 0.9974 - val_loss: 0.0108\n",
      "Epoch 8/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9991 - val_loss: 0.0068\n",
      "Epoch 9/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.9992 - loss: 0.0044 - val_accuracy: 0.9982 - val_loss: 0.0103\n",
      "Epoch 10/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.9984 - loss: 0.0070 - val_accuracy: 0.9982 - val_loss: 0.0089\n",
      "Epoch 11/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9991 - val_loss: 0.0118\n",
      "Epoch 12/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.9991 - val_loss: 0.0070\n",
      "Epoch 13/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9930 - val_loss: 0.0418\n",
      "Epoch 14/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.9953 - loss: 0.0210 - val_accuracy: 0.9991 - val_loss: 0.0037\n",
      "Epoch 15/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 0.9987 - loss: 0.0053 - val_accuracy: 0.9991 - val_loss: 0.0042\n",
      "Epoch 16/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.9986 - loss: 0.0031 - val_accuracy: 0.9991 - val_loss: 0.0048\n",
      "Epoch 17/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.9999 - loss: 8.6044e-04 - val_accuracy: 0.9991 - val_loss: 0.0049\n",
      "Epoch 18/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.9998 - loss: 9.5709e-04 - val_accuracy: 0.9991 - val_loss: 0.0050\n",
      "Epoch 19/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 2.2174e-04 - val_accuracy: 0.9991 - val_loss: 0.0052\n",
      "Epoch 20/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 0.9987 - loss: 0.0030 - val_accuracy: 0.9991 - val_loss: 0.0059\n",
      "Epoch 21/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 7.9828e-05 - val_accuracy: 0.9991 - val_loss: 0.0061\n",
      "Epoch 22/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 2.4101e-04 - val_accuracy: 0.9991 - val_loss: 0.0062\n",
      "Epoch 23/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 8.5575e-05 - val_accuracy: 0.9991 - val_loss: 0.0065\n",
      "Epoch 24/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 7.5056e-05 - val_accuracy: 0.9991 - val_loss: 0.0066\n",
      "Epoch 25/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 12ms/step - accuracy: 1.0000 - loss: 9.5303e-05 - val_accuracy: 0.9991 - val_loss: 0.0069\n",
      "Epoch 26/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 1.0000 - loss: 4.8807e-05 - val_accuracy: 0.9991 - val_loss: 0.0072\n",
      "Epoch 27/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 2.0230e-05 - val_accuracy: 0.9991 - val_loss: 0.0073\n",
      "Epoch 28/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 4.3904e-05 - val_accuracy: 0.9991 - val_loss: 0.0076\n",
      "Epoch 29/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 11ms/step - accuracy: 1.0000 - loss: 6.6452e-05 - val_accuracy: 0.9982 - val_loss: 0.0152\n",
      "Epoch 30/30\n",
      "\u001B[1m379/379\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 10ms/step - accuracy: 0.9918 - loss: 0.0293 - val_accuracy: 0.9982 - val_loss: 0.0179\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9971 - loss: 0.0307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.82%\n",
      "Model saved as lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('csv/output.csv')\n",
    "\n",
    "# Drop rows with NaN values\n",
    "#data.dropna(inplace=True)\n",
    "\n",
    "# Encode the class labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['class_name'] = label_encoder.fit_transform(data['class_name'])\n",
    "\n",
    "# Extract features and labels\n",
    "features = data[['right_shoulder_angle',\n",
    "            'right_elbow_angle',\n",
    "            'right_hip_angle',\n",
    "            'right_knee_angle',\n",
    "            'left_shoulder_angle',\n",
    "            'left_elbow_angle',\n",
    "            'left_hip_angle',\n",
    "            'left_knee_angle']].values\n",
    "\n",
    "labels = data['class_name'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 40\n",
    "\n",
    "# Prepare sequences for LSTM\n",
    "def create_sequences(data, labels, seq_length):\n",
    "    sequences = []\n",
    "    labels_seq = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i + seq_length]\n",
    "        label_seq = labels[i + seq_length - 1]\n",
    "        sequences.append(seq)\n",
    "        labels_seq.append(label_seq)\n",
    "    return np.array(sequences), np.array(labels_seq)\n",
    "\n",
    "X, y = create_sequences(features, labels, sequence_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(sequence_length, X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=12, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the model\n",
    "model.save('lstm_model.h5')\n",
    "print('Model saved as lstm_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77215f07-9b56-4e86-b24a-0d71dc937c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Saving the LabelEncoder after training\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
